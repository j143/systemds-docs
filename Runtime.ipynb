{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Distributed Matrix Representation](#DistributedMatrixRepresentation)\n",
    "\t* [Collection of Matrix Blocks (and keys)](#CollectionofMatrixBlocks)\n",
    "\t* [Partitioning](#Partitioning)\n",
    "\t* [Common Matrix Block Representations](#CommonMatrixBlockRepresentations)\n",
    "* [Buffer Pool Overview](#BufferPoolOverview)\n",
    "* [Spark-specific Optimizations](#SparkspecificOptimizations)\n",
    "\t* [Partitioning-preserving ops](#PartitioningPreservingOps)\n",
    "\t* [Partitioning-exploiting ops](#PartitioningExploitingOps)\n",
    "* [Spark-specific rewrites](#SparkspecificRewrites)\n",
    "\n",
    "\n",
    "# Distributed Matrix Representation <a id=\"DistributedMatrixRepresentation\"></a>\n",
    "\n",
    "## Collection of “Matrix Blocks” (and keys)  <a id=\"CollectionofMatrixBlocks\"></a>\n",
    "- “tiles”, a.k.a. “chunks”\n",
    "- Bag semantics (duplicates, unordered)\n",
    "- Logical (Fixed-Size) Blocking \n",
    "  - Pros: join processing / independence\n",
    "  - Cons: (sparsity skew)\n",
    "- E.g., SystemML on Spark:`JavaPairRDD<MatrixIndexes,MatrixBlock>`\n",
    "- Blocks encoded independently (dense/sparse)\n",
    "\n",
    "## Partitioning  <a id=\"Partitioning\"></a>\n",
    "- Logical Partitioning (e.g., row-/column-wise)\n",
    "- Physical Partitioning (e.g., Hash / Grid)\n",
    "\n",
    "![Partitioning](images/MBPartitioning.png)\n",
    "\n",
    "\n",
    "## Common Matrix Block Representations <a id=\"CommonMatrixBlockRepresentations\"></a>\n",
    "- Dense (row-major arrays)\n",
    "- MCSR (modified CSR)\n",
    "- CSR (compressed sparse rows), CSC\n",
    "- COO (Coordinate matrix)\n",
    "\n",
    "![Common Matrix Block Representation](images/MBRepresentation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemML Version: 1.0.0-SNAPSHOT\n",
      "SystemML Built-Time: 2017-08-14 01:28:05 UTC\n"
     ]
    }
   ],
   "source": [
    "from systemml import MLContext, dml\n",
    "ml = MLContext(sc)\n",
    "\n",
    "print \"SystemML Version:\", ml.version()\n",
    "print \"SystemML Built-Time:\", ml.buildTime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below example demonstrates logical blocking of 3400 X 2700 matrix with block size of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printMatrixBlockInfo(X):\n",
    "    \"\"\"\n",
    "    Simple utility to print the information about the matrix blocks contained in  X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Matrix\n",
    "    \"\"\"\n",
    "    mbs = X._java_matrix.toBinaryBlocks().values().collect()\n",
    "    for i in range(mbs.size()):\n",
    "        mb = mbs.get(i)\n",
    "        sparse = str(mb.isInSparseFormat())\n",
    "        nnz = str(mb.getNonZeros())\n",
    "        size = str(mb.getNumRows()) + \" X \" +  str(mb.getNumColumns())\n",
    "        print(\"sparse? = \" + sparse + \", nonzeros = \" + nnz + \", size: \" + size)\n",
    "\n",
    "prog = \"\"\"\n",
    "X = rand(rows=3400, cols=2700, sparsity=0.4)     # generate a random matrix with sparsity 0.4\n",
    "\"\"\"\n",
    "X = ml.execute(dml(prog).output(\"X\")).get(\"X\")\n",
    "printMatrixBlockInfo(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer Pool Overview <a id=\"BufferPoolOverview\"></a>\n",
    "\n",
    "- Motivation\n",
    "  - Exchange of intermediates between local and remote operations (HDFS, RDDs, GPU device memory)\n",
    "  - Eviction of in-memory objects (integrated with garbage collector)\n",
    "- Primitives: acquireRead, acquireModify, release, exportData, getRdd, getBroadcast\n",
    "- Spark Specifics\n",
    "  - Lineage tracking\n",
    "  - RDDs/broadcasts\n",
    "  - Guarded RDD collect/parallelize\n",
    "  - Partitioned Broadcast variables\n",
    "  \n",
    "![Buffer Pool](images/BufferPool.png)\n",
    "\n",
    "# Spark-specific Optimizations <a id=\"SparkspecificOptimizations\"></a>\n",
    "\n",
    "## Partitioning-preserving ops  <a id=\"PartitioningPreservingOps\"></a>\n",
    "- Op is partitioning-preserving if key not changed (guaranteed)\n",
    "-  Implicit: Use restrictive APIs (mapValues() vs mapToPair())\n",
    "-  Explicit: Partition computation w/ declaration of partitioning-preserving (memory-efficiency via “lazy iterators”)\n",
    "\n",
    "## Partitioning-exploiting ops <a id=\"PartitioningExploitingOps\"></a>\n",
    "-  Implicit: Operations based on join, cogroup, etc\n",
    "-  Explicit: Custom physical operators on original keys (e.g., zipmm)\n",
    "\n",
    "Example: **Partitioning-Exploiting ZIPMM**\n",
    "\n",
    "![Zipmm](images/Zipmm.png)\n",
    "\n",
    "## Spark-specific rewrites <a id=\"SparkspecificRewrites\"></a>\n",
    "\n",
    "![Spark specific optimization](images/Spark-specific-optimization.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
